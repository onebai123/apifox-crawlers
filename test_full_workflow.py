#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import time
from utils.downloader import ApiDownloader
from utils.parser import LlmsParser
from utils.processor import ApiProcessor

def test_full_workflow():
    """æµ‹è¯•å®Œæ•´çš„ä¸‰é˜¶æ®µå·¥ä½œæµç¨‹"""
    
    base_url = "https://wddotnlfvy.apifox.cn"
    
    print("=" * 60)
    print("ğŸš€ å¼€å§‹æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹")
    print("=" * 60)
    
    # é˜¶æ®µ1ï¼šä¸‹è½½å’Œè§£æ
    print("\nğŸ“¥ é˜¶æ®µ1ï¼šä¸‹è½½llms.txtå¹¶è§£æAPIé“¾æ¥")
    print("-" * 40)
    
    downloader = ApiDownloader(base_url)
    parser = LlmsParser(base_url)
    
    # ä¸‹è½½llms.txt
    print("æ­£åœ¨ä¸‹è½½llms.txt...")
    if downloader.download_llms_txt():
        print("âœ… llms.txtä¸‹è½½æˆåŠŸ")
    else:
        print("âŒ llms.txtä¸‹è½½å¤±è´¥")
        return False
    
    # è§£æé“¾æ¥
    print("æ­£åœ¨è§£æAPIé“¾æ¥...")
    with open('data/01/llms.txt', 'r', encoding='utf-8') as f:
        content = f.read()
    
    api_links = parser.parse_llms_content(content)
    if api_links:
        print(f"âœ… è§£ææˆåŠŸï¼Œæ‰¾åˆ° {len(api_links)} ä¸ªAPIé“¾æ¥")
        
        # ä¿å­˜é“¾æ¥åˆ°url.txt
        with open('data/01/url.txt', 'w', encoding='utf-8') as f:
            f.write("# è§£æå‡ºçš„APIæ–‡æ¡£é“¾æ¥\n\n")
            for i, link in enumerate(api_links, 1):
                f.write(f"{i}. {link['title']}\n")
                f.write(f"   URL: {link['url']}\n")
                f.write(f"   å®Œæ•´URL: {link['full_url']}\n\n")
        print("âœ… url.txtæ–‡ä»¶å·²ç”Ÿæˆ")
    else:
        print("âŒ è§£æå¤±è´¥")
        return False
    
    # ä¸‹è½½MDæ–‡ä»¶
    print("æ­£åœ¨ä¸‹è½½MDæ–‡ä»¶...")
    downloaded_files = downloader.download_md_files(api_links)
    success_count = len(downloaded_files)
    total_count = len(api_links)
    print(f"âœ… MDæ–‡ä»¶ä¸‹è½½å®Œæˆï¼š{success_count}/{total_count}")
    
    # é˜¶æ®µ2ï¼šå¤„ç†å’Œè½¬æ¢
    print("\nğŸ”„ é˜¶æ®µ2ï¼šMDæ–‡ä»¶æ¸…æ´—å’ŒYAMLè½¬æ¢")
    print("-" * 40)
    
    processor = ApiProcessor()
    
    # å¤„ç†MDæ–‡ä»¶
    # å¤„ç†MDæ–‡ä»¶
    print("æ­£åœ¨å¤„ç†MDæ–‡ä»¶...")
    stage2_result = processor.stage2_clean_and_convert()
    if stage2_result and 'processed' in stage2_result:
        print(f"âœ… é˜¶æ®µ2å¤„ç†å®Œæˆï¼š{stage2_result['processed']} ä¸ªæ–‡ä»¶")
        print(f"âœ… æœ‰æ•ˆæ–‡ä»¶ï¼š{stage2_result['valid']} ä¸ª")
    else:
        print("âŒ é˜¶æ®µ2å¤„ç†å¤±è´¥")
        return False
    
    # é˜¶æ®µ3ï¼šæœ€ç»ˆåˆå¹¶
    print("\nğŸ“‹ é˜¶æ®µ3ï¼šæœ€ç»ˆYAMLåˆå¹¶")
    print("-" * 40)
    
    print("æ­£åœ¨åˆå¹¶YAMLæ–‡ä»¶...")
    stage3_result = processor.stage3_merge_final()
    
    # æ£€æŸ¥è¿”å›ç»“æœæ ¼å¼
    if isinstance(stage3_result, dict) and 'merged_files' in stage3_result:
        merged_count = stage3_result['merged_files']
        total_categories = stage3_result.get('total_categories', merged_count)
        print(f"âœ… é˜¶æ®µ3åˆå¹¶å®Œæˆï¼š{merged_count}/{total_categories} ä¸ªåˆ†ç±»")
        
        # æ£€æŸ¥æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
        final_files = []
        if os.path.exists(processor.final_dir):
            final_files = [f for f in os.listdir(processor.final_dir) if f.endswith('.yml')]
        print(f"ğŸ“ æœ€ç»ˆæ–‡ä»¶æ•°é‡ï¼š{len(final_files)} ä¸ª")
        
        # åªè¦æœ‰æˆåŠŸåˆå¹¶çš„åˆ†ç±»å°±ç®—æˆåŠŸ
        if merged_count > 0:
            stage3_result = merged_count  # ä¸ºäº†åç»­ç»Ÿè®¡æ˜¾ç¤º
        else:
            print("âŒ é˜¶æ®µ3åˆå¹¶å¤±è´¥ï¼šæ²¡æœ‰æˆåŠŸåˆå¹¶ä»»ä½•åˆ†ç±»")
            return False
    else:
        print("âŒ é˜¶æ®µ3åˆå¹¶å¤±è´¥")
        return False
    print("\n" + "=" * 60)
    print("ğŸ‰ å®Œæ•´å·¥ä½œæµç¨‹æµ‹è¯•æˆåŠŸï¼")
    print("=" * 60)
    
    # æ˜¾ç¤ºç»“æœç»Ÿè®¡
    print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡ï¼š")
    print(f"   - APIé“¾æ¥æ•°é‡ï¼š{len(api_links)}")
    print(f"   - MDæ–‡ä»¶ä¸‹è½½ï¼š{success_count}/{total_count}")
    print(f"   - YAMLæ–‡ä»¶å¤„ç†ï¼š{stage2_result['processed']}")
    print(f"   - æœ€ç»ˆåˆå¹¶åˆ†ç±»ï¼š{stage3_result}")
    
    return True

if __name__ == "__main__":
    test_full_workflow()